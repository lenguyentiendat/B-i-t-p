{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_1mT-OWOKv0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpnapEHw7nA9",
        "outputId": "0f6eae1a-def2-41ab-b222-f4cd807e1c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CS114"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd_5hjd-k8Xm",
        "outputId": "18f062ad-03f6-406a-e3f6-0868b76eb64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "d093f12f-29ed-4184-b20a-6550f8748630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15287, done.\u001b[K\n",
            "remote: Total 15287 (delta 0), reused 0 (delta 0), pack-reused 15287\u001b[K\n",
            "Receiving objects: 100% (15287/15287), 14.18 MiB | 8.24 MiB/s, done.\n",
            "Resolving deltas: 100% (10489/10489), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git  # clone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gSZt0P3sr9A",
        "outputId": "d34ce1ce-1413-402b-b30c-8d307c2a6a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-116-g5c91dae Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 25.6/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ily0dvOEXLXj"
      },
      "source": [
        "#Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii6C8et4XSd7"
      },
      "outputs": [],
      "source": [
        "# Weights & Biases  (optional)\n",
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 1 --epochs 5 --data /content/drive/MyDrive/CS114/Dataset/dataset.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FDL9NIEu8Pk",
        "outputId": "0db25875-4dd2-420f-b531-bf4aba0f9948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/CS114/Dataset/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-116-g5c91dae Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-01 11:17:46.205435: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-01 11:17:47.149591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 11:17:47.149715: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 11:17:47.149735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 179MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=28\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     89001  models.yolo.Detect                      [28, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7095145 parameters, 7095145 gradients, 16.2 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CS114/Dataset/labels/train... 1199 images, 1 backgrounds, 0 corrupt: 100% 1200/1200 [25:54<00:00,  1.30s/it]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/CS114/Dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB ram): 100% 1200/1200 [06:17<00:00,  3.18it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CS114/Dataset/labels/val... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [01:49<00:00,  1.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/CS114/Dataset/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 150/150 [00:49<00:00,  3.04it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.46 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4     0.484G    0.08338    0.06373    0.07786         16        640: 100% 1200/1200 [02:10<00:00,  9.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:06<00:00, 12.32it/s]\n",
            "                   all        150        726     0.0172      0.364     0.0388     0.0199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4     0.614G    0.05435    0.05681    0.06647          4        640: 100% 1200/1200 [02:07<00:00,  9.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 16.71it/s]\n",
            "                   all        150        726      0.636       0.14     0.0687     0.0326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4     0.614G    0.04916    0.05673    0.06348         10        640: 100% 1200/1200 [02:06<00:00,  9.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 15.19it/s]\n",
            "                   all        150        726      0.692      0.167      0.094     0.0518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4     0.614G     0.0431    0.05562    0.06225         14        640: 100% 1200/1200 [02:08<00:00,  9.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:05<00:00, 14.86it/s]\n",
            "                   all        150        726      0.667      0.204      0.123     0.0647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4     0.686G    0.03974    0.05329    0.05929          7        640: 100% 1200/1200 [02:07<00:00,  9.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:05<00:00, 14.68it/s]\n",
            "                   all        150        726      0.667      0.232      0.169      0.101\n",
            "\n",
            "5 epochs completed in 0.186 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7085641 parameters, 0 gradients, 16.0 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 15.61it/s]\n",
            "                   all        150        726      0.667      0.232      0.169      0.101\n",
            "                bottle        150         47      0.106      0.745      0.114     0.0702\n",
            "                   can        150         11     0.0212          1      0.608      0.393\n",
            "          glass bottle        150         77          1          0      0.153     0.0937\n",
            "           plastic bag        150         38     0.0678      0.763      0.136     0.0926\n",
            "            carton box        150         11          1          0     0.0173     0.0095\n",
            "              foam box        150         96      0.124      0.802      0.207      0.101\n",
            "         plastic glass        150        127      0.169      0.743      0.207      0.104\n",
            "        drinking straw        150         17      0.334      0.235       0.19      0.059\n",
            "                tobaco        150         34      0.261      0.706      0.574      0.336\n",
            "         plastic spoon        150         13          1          0      0.183      0.126\n",
            "         plastic plate        150          8          1          0     0.0582     0.0205\n",
            "          plastic bowl        150         16          1      0.128      0.604      0.381\n",
            "           plastic cap        150         10          1          0     0.0307     0.0198\n",
            "           plastic box        150          8          1          0      0.336      0.218\n",
            "           milk bottle        150         17          0          0     0.0376     0.0195\n",
            "            zipper bag        150         15          1          0      0.101     0.0699\n",
            "             trash bag        150         76      0.194      0.882      0.437      0.246\n",
            "                  mask        150         15          1          0       0.21      0.154\n",
            "       sausage package        150          1          1          0     0.0226    0.00865\n",
            "         snack package        150         39     0.0772     0.0256      0.086     0.0494\n",
            "               clothes        150          2          1          0          0          0\n",
            "               coconut        150          1          1          0    0.00181    0.00127\n",
            "                 broom        150          4          1          0          0          0\n",
            "               pillbox        150          2          1          0          0          0\n",
            "          PP woven bag        150         35          1          0      0.067     0.0298\n",
            "                 shoes        150          6          1          0     0.0214     0.0164\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 1 --epochs 21 --data /content/drive/MyDrive/CS114/Dataset/dataset.yaml --weights /content/drive/MyDrive/CS114/yolov5/runs/train/exp/weights/last.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNFHftB3IGwm",
        "outputId": "149a57fc-c16d-49c5-c671-261894c55f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/CS114/yolov5/runs/train/exp/weights/last.pt, cfg=, data=/content/drive/MyDrive/CS114/Dataset/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=21, batch_size=1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-116-g5c91dae Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-01 12:05:31.034110: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-01 12:05:33.462387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 12:05:33.462543: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 12:05:33.462565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     89001  models.yolo.Detect                      [28, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7095145 parameters, 7095145 gradients, 16.2 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from /content/drive/MyDrive/CS114/yolov5/runs/train/exp/weights/last.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CS114/Dataset/labels/train.cache... 1199 images, 1 backgrounds, 0 corrupt: 100% 1200/1200 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB ram): 100% 1200/1200 [05:55<00:00,  3.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CS114/Dataset/labels/val.cache... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 150/150 [00:50<00:00,  2.94it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.46 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 21 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/20     0.484G    0.03437    0.05302    0.05784         16        640: 100% 1200/1200 [02:17<00:00,  8.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 15.42it/s]\n",
            "                   all        150        726      0.662      0.254       0.18      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/20     0.768G    0.03858    0.04896    0.05571          4        640: 100% 1200/1200 [02:13<00:00,  9.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 18.85it/s]\n",
            "                   all        150        726      0.567      0.265      0.203      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/20     0.768G    0.04366    0.04951    0.05281         10        640: 100% 1200/1200 [02:08<00:00,  9.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 15.37it/s]\n",
            "                   all        150        726       0.67      0.256      0.197     0.0999\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/20     0.768G    0.04309     0.0494     0.0503         14        640: 100% 1200/1200 [02:05<00:00,  9.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 17.70it/s]\n",
            "                   all        150        726      0.649      0.274       0.24      0.123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/20     0.768G    0.04001    0.04897    0.04676          7        640: 100% 1200/1200 [02:05<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 19.55it/s]\n",
            "                   all        150        726      0.651      0.306       0.26      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/20     0.768G    0.03865    0.04952     0.0436          9        640: 100% 1200/1200 [02:05<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.81it/s]\n",
            "                   all        150        726       0.63      0.376      0.346      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/20     0.768G    0.03693    0.04821    0.04032         13        640: 100% 1200/1200 [02:03<00:00,  9.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 16.64it/s]\n",
            "                   all        150        726      0.703      0.336       0.38       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/20     0.768G    0.03622    0.04823    0.03856          5        640: 100% 1200/1200 [02:02<00:00,  9.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.18it/s]\n",
            "                   all        150        726      0.626       0.42      0.375      0.223\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/20     0.768G    0.03461    0.04684    0.03614         11        640: 100% 1200/1200 [02:01<00:00,  9.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 18.03it/s]\n",
            "                   all        150        726      0.695      0.388      0.431      0.273\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/20     0.768G    0.03369    0.04618    0.03442          6        640: 100% 1200/1200 [02:04<00:00,  9.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 17.89it/s]\n",
            "                   all        150        726      0.742      0.357      0.461      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/20     0.768G    0.03262     0.0454    0.03309         17        640: 100% 1200/1200 [02:05<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.27it/s]\n",
            "                   all        150        726      0.729      0.379      0.498      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/20     0.768G     0.0321    0.04432    0.03167         11        640: 100% 1200/1200 [02:06<00:00,  9.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 19.84it/s]\n",
            "                   all        150        726      0.788      0.349      0.521      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/20     0.768G     0.0311    0.04304    0.03023          4        640: 100% 1200/1200 [02:08<00:00,  9.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.92it/s]\n",
            "                   all        150        726      0.814      0.363      0.529      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/20     0.768G    0.03071    0.04446    0.02983          4        640: 100% 1200/1200 [02:08<00:00,  9.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.52it/s]\n",
            "                   all        150        726      0.672      0.478      0.547       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/20     0.768G    0.03019    0.04324    0.02781          9        640: 100% 1200/1200 [02:04<00:00,  9.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.95it/s]\n",
            "                   all        150        726      0.658      0.518       0.55      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/20     0.768G     0.0295    0.04257    0.02697          8        640: 100% 1200/1200 [02:03<00:00,  9.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.20it/s]\n",
            "                   all        150        726      0.629      0.549      0.559      0.373\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/20     0.768G    0.02873     0.0429    0.02545          8        640: 100% 1200/1200 [02:03<00:00,  9.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.22it/s]\n",
            "                   all        150        726      0.745      0.521      0.584      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/20     0.768G    0.02824    0.04214     0.0252         13        640: 100% 1200/1200 [02:03<00:00,  9.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 17.04it/s]\n",
            "                   all        150        726       0.79      0.516        0.6      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/20     0.768G    0.02766    0.04193    0.02406          6        640: 100% 1200/1200 [02:02<00:00,  9.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.78it/s]\n",
            "                   all        150        726      0.693      0.584      0.607      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/20     0.768G    0.02729    0.04215    0.02301         18        640: 100% 1200/1200 [02:04<00:00,  9.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 22.03it/s]\n",
            "                   all        150        726      0.804      0.526      0.616      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/20     0.768G    0.02643    0.04113    0.02184          6        640: 100% 1200/1200 [02:02<00:00,  9.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 22.26it/s]\n",
            "                   all        150        726      0.772      0.545      0.608      0.424\n",
            "\n",
            "21 epochs completed in 0.761 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7085641 parameters, 0 gradients, 16.0 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 17.28it/s]\n",
            "                   all        150        726      0.772      0.545      0.608      0.424\n",
            "                bottle        150         47      0.706      0.809      0.805      0.545\n",
            "                   can        150         11      0.597      0.909      0.858      0.731\n",
            "          glass bottle        150         77       0.96      0.922      0.961      0.659\n",
            "           plastic bag        150         38      0.661       0.72      0.782       0.49\n",
            "            carton box        150         11          1          0      0.114     0.0859\n",
            "              foam box        150         96       0.69      0.781      0.833      0.495\n",
            "         plastic glass        150        127      0.705      0.787      0.789      0.499\n",
            "        drinking straw        150         17      0.528      0.706      0.709      0.426\n",
            "                tobaco        150         34      0.827      0.794      0.867      0.599\n",
            "         plastic spoon        150         13       0.79      0.869      0.912      0.618\n",
            "         plastic plate        150          8      0.429      0.625      0.649       0.54\n",
            "          plastic bowl        150         16       0.53      0.776      0.724      0.484\n",
            "           plastic cap        150         10      0.589        0.6      0.553      0.369\n",
            "           plastic box        150          8          1      0.445      0.913      0.516\n",
            "           milk bottle        150         17      0.555      0.661      0.641      0.429\n",
            "            zipper bag        150         15          1          0      0.183      0.154\n",
            "             trash bag        150         76      0.598      0.697      0.723      0.495\n",
            "                  mask        150         15          1      0.332       0.83      0.585\n",
            "       sausage package        150          1      0.519          1      0.995      0.895\n",
            "         snack package        150         39       0.75      0.846      0.904       0.61\n",
            "               clothes        150          2          1          0          0          0\n",
            "               coconut        150          1          1          0    0.00132    0.00119\n",
            "                 broom        150          4          1          0          0          0\n",
            "               pillbox        150          2      0.627      0.882      0.828      0.629\n",
            "          PP woven bag        150         35          1          0      0.179      0.119\n",
            "                 shoes        150          6          1          0     0.0503     0.0388\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 1 --epochs 41 --data /content/drive/MyDrive/CS114/Dataset/dataset.yaml --weights /content/drive/MyDrive/CS114/yolov5/runs/train/exp2/weights/last.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwwwra1yRA3i",
        "outputId": "17185e1c-0e9c-4739-bf80-ac96b46e8480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/CS114/yolov5/runs/train/exp2/weights/last.pt, cfg=, data=/content/drive/MyDrive/CS114/Dataset/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=41, batch_size=1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-116-g5c91dae Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-01 12:59:48.973283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-01 12:59:51.230514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 12:59:51.230698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 12:59:51.230723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     89001  models.yolo.Detect                      [28, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7095145 parameters, 7095145 gradients, 16.2 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from /content/drive/MyDrive/CS114/yolov5/runs/train/exp2/weights/last.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CS114/Dataset/labels/train.cache... 1199 images, 1 backgrounds, 0 corrupt: 100% 1200/1200 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB ram): 100% 1200/1200 [05:52<00:00,  3.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CS114/Dataset/labels/val.cache... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 150/150 [00:49<00:00,  3.05it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.46 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp3/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
            "Starting training for 41 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/40     0.484G    0.02676    0.04143    0.02227         16        640: 100% 1200/1200 [02:12<00:00,  9.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 19.60it/s]\n",
            "                   all        150        726      0.749      0.558      0.608      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/40     0.487G    0.03051    0.03985    0.02216          4        640: 100% 1200/1200 [02:04<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 17.93it/s]\n",
            "                   all        150        726      0.774      0.565      0.609      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/40     0.487G    0.03496    0.04183    0.02265         10        640: 100% 1200/1200 [02:03<00:00,  9.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.21it/s]\n",
            "                   all        150        726      0.687      0.582      0.613      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/40     0.487G    0.03561    0.04302    0.02429         14        640: 100% 1200/1200 [02:06<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.61it/s]\n",
            "                   all        150        726      0.739      0.558      0.621      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/40     0.487G    0.03451    0.04238    0.02333          7        640: 100% 1200/1200 [02:07<00:00,  9.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.27it/s]\n",
            "                   all        150        726      0.739      0.519      0.582      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/40     0.487G    0.03391     0.0431    0.02273          9        640: 100% 1200/1200 [02:07<00:00,  9.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 19.79it/s]\n",
            "                   all        150        726      0.753      0.536      0.594      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/40     0.487G    0.03308    0.04241    0.02168         13        640: 100% 1200/1200 [02:11<00:00,  9.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.67it/s]\n",
            "                   all        150        726      0.758       0.55      0.655      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/40     0.487G     0.0334    0.04302    0.02136          5        640: 100% 1200/1200 [02:09<00:00,  9.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.70it/s]\n",
            "                   all        150        726      0.792      0.531      0.625      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/40     0.487G    0.03177    0.04189    0.02066         11        640: 100% 1200/1200 [02:08<00:00,  9.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.39it/s]\n",
            "                   all        150        726      0.786      0.533      0.603      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/40     0.533G    0.03227    0.04174    0.01922          6        640: 100% 1200/1200 [02:04<00:00,  9.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 18.91it/s]\n",
            "                   all        150        726      0.777      0.563       0.63      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/40     0.533G    0.03147    0.04123    0.01855         17        640: 100% 1200/1200 [02:05<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 16.25it/s]\n",
            "                   all        150        726      0.855      0.527      0.634      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/40     0.533G    0.03139     0.0407    0.01817         11        640: 100% 1200/1200 [02:06<00:00,  9.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 19.37it/s]\n",
            "                   all        150        726      0.705      0.609      0.634      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/40     0.533G    0.03074    0.04023    0.01777          4        640: 100% 1200/1200 [02:04<00:00,  9.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.71it/s]\n",
            "                   all        150        726      0.811      0.573      0.643       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/40     0.533G    0.02998    0.04131    0.01761          4        640: 100% 1200/1200 [02:05<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.26it/s]\n",
            "                   all        150        726      0.765      0.574      0.664      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/40     0.533G    0.03031    0.04076    0.01632          9        640: 100% 1200/1200 [02:05<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 17.30it/s]\n",
            "                   all        150        726      0.752      0.599      0.665      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/40     0.533G    0.03009    0.04023     0.0164          8        640: 100% 1200/1200 [02:06<00:00,  9.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.31it/s]\n",
            "                   all        150        726      0.716      0.612      0.667      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/40     0.533G    0.02935    0.04072    0.01565          8        640: 100% 1200/1200 [02:10<00:00,  9.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 18.48it/s]\n",
            "                   all        150        726      0.784      0.615       0.69      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/40     0.533G    0.02913     0.0402    0.01569         13        640: 100% 1200/1200 [02:06<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.18it/s]\n",
            "                   all        150        726      0.728      0.623      0.675      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/40     0.598G    0.02898    0.04029     0.0161          6        640: 100% 1200/1200 [02:07<00:00,  9.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 22.04it/s]\n",
            "                   all        150        726      0.734      0.623      0.676      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/40     0.598G    0.02941    0.04072    0.01459         18        640: 100% 1200/1200 [02:04<00:00,  9.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 19.81it/s]\n",
            "                   all        150        726      0.777      0.641      0.672      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/40     0.598G     0.0285    0.04008     0.0141          6        640: 100% 1200/1200 [02:08<00:00,  9.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 19.82it/s]\n",
            "                   all        150        726      0.751      0.672      0.679      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/40     0.598G     0.0282    0.03962    0.01405          5        640: 100% 1200/1200 [02:07<00:00,  9.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 16.64it/s]\n",
            "                   all        150        726      0.811      0.625      0.696       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/40     0.598G    0.02829    0.03982    0.01432         21        640: 100% 1200/1200 [02:08<00:00,  9.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 15.77it/s]\n",
            "                   all        150        726       0.79      0.624      0.695      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/40     0.598G    0.02779    0.03905    0.01445         10        640: 100% 1200/1200 [02:06<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.12it/s]\n",
            "                   all        150        726      0.795      0.625      0.701      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/40     0.598G    0.02747    0.03926    0.01318          8        640: 100% 1200/1200 [02:06<00:00,  9.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.61it/s]\n",
            "                   all        150        726      0.793      0.642      0.726      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/40     0.598G    0.02731    0.03892    0.01261         12        640: 100% 1200/1200 [02:09<00:00,  9.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.04it/s]\n",
            "                   all        150        726       0.81      0.626       0.71      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/40     0.598G    0.02696    0.03788    0.01243         10        640: 100% 1200/1200 [02:09<00:00,  9.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.79it/s]\n",
            "                   all        150        726      0.801      0.645      0.719      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/40     0.598G    0.02671     0.0387    0.01235          2        640: 100% 1200/1200 [02:09<00:00,  9.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.42it/s]\n",
            "                   all        150        726      0.822      0.616       0.73      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/40     0.598G    0.02615     0.0379    0.01181          8        640: 100% 1200/1200 [02:08<00:00,  9.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.52it/s]\n",
            "                   all        150        726      0.742      0.689      0.705      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/40     0.598G    0.02612    0.03785    0.01237          6        640: 100% 1200/1200 [02:10<00:00,  9.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.85it/s]\n",
            "                   all        150        726       0.75      0.692      0.716       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/40     0.598G    0.02615     0.0379    0.01153          4        640: 100% 1200/1200 [02:10<00:00,  9.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.59it/s]\n",
            "                   all        150        726      0.828      0.646      0.715      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/40     0.598G    0.02538     0.0366    0.01072          5        640: 100% 1200/1200 [02:09<00:00,  9.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 22.28it/s]\n",
            "                   all        150        726       0.84      0.647      0.724      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/40     0.598G    0.02546    0.03683    0.01118         10        640: 100% 1200/1200 [02:09<00:00,  9.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.47it/s]\n",
            "                   all        150        726      0.812      0.657      0.719      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/40     0.598G    0.02512    0.03679    0.01055          7        640: 100% 1200/1200 [02:09<00:00,  9.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.82it/s]\n",
            "                   all        150        726      0.802      0.657      0.718      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/40     0.598G    0.02435    0.03719   0.009966          9        640: 100% 1200/1200 [02:08<00:00,  9.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 21.50it/s]\n",
            "                   all        150        726      0.822      0.656      0.717      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/40     0.598G    0.02453    0.03733   0.009386          5        640: 100% 1200/1200 [02:08<00:00,  9.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 22.20it/s]\n",
            "                   all        150        726      0.815      0.644      0.719      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/40     0.598G    0.02393     0.0356   0.009796          6        640: 100% 1200/1200 [02:08<00:00,  9.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.23it/s]\n",
            "                   all        150        726      0.803      0.659      0.712      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/40     0.598G    0.02404    0.03603   0.009765          4        640: 100% 1200/1200 [02:04<00:00,  9.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 20.15it/s]\n",
            "                   all        150        726      0.824      0.652      0.728      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/40     0.598G    0.02382    0.03573   0.008635          6        640: 100% 1200/1200 [02:03<00:00,  9.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:03<00:00, 22.09it/s]\n",
            "                   all        150        726      0.837      0.642      0.723      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/40     0.598G    0.02372    0.03544   0.009184          6        640: 100% 1200/1200 [02:03<00:00,  9.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 75/75 [00:04<00:00, 17.71it/s]\n",
            "                   all        150        726      0.832      0.641      0.723      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/40     0.598G    0.02363    0.03594    0.00868          3        640:  67% 806/1200 [01:23<00:36, 10.92it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 1 --epochs 11 --data /content/drive/MyDrive/CS114/Dataset/dataset.yaml --weights /content/drive/MyDrive/CS114/yolov5/runs/train/exp3/weights/best.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-mHgNpTx6i6",
        "outputId": "c7acbd94-c83c-49ab-f00b-7a8609db8566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/CS114/yolov5/runs/train/exp3/weights/best.pt, cfg=, data=/content/drive/MyDrive/CS114/Dataset/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=11, batch_size=1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-116-g5c91dae Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-01 16:17:08.207496: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-01 16:17:09.083846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 16:17:09.084060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 16:17:09.084091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     89001  models.yolo.Detect                      [28, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7095145 parameters, 7095145 gradients, 16.2 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from /content/drive/MyDrive/CS114/yolov5/runs/train/exp3/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1hac8RVxweWbqy5AoUaFIVDspywdktWHv/CS114/Dataset/labels/train... 12 images, 0 backgrounds, 0 corrupt:   1% 12/1200 [00:19<30:52,  1.56s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxQgWhV8gxqb"
      },
      "source": [
        "#Val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKyVNUuq0S-A",
        "outputId": "8b651040-2e7e-4ffc-ee11-d65444120f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/CS114/Dataset/dataset.yaml, weights=['/content/drive/MyDrive/CS114/yolov5/runs/train/exp7/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.45, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v7.0-102-ge4d8360 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7085641 parameters, 0 gradients, 16.0 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1hac8RVxweWbqy5AoUaFIVDspywdktWHv/CS114/Dataset/labels/test... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [00:44<00:00,  3.36it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1hac8RVxweWbqy5AoUaFIVDspywdktWHv/CS114/Dataset/labels/test.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:52<00:00, 10.49s/it]\n",
            "                   all        150        771      0.801      0.714      0.757      0.536\n",
            "                bottle        150         30      0.965      0.926      0.924      0.706\n",
            "                   can        150         11      0.713          1      0.927      0.747\n",
            "          glass bottle        150         45      0.993      0.956      0.956      0.726\n",
            "           plastic bag        150         67      0.608       0.97      0.743      0.522\n",
            "                 paper        150         20       0.57      0.596      0.467      0.214\n",
            "            carton box        150         23       0.53      0.392      0.611      0.432\n",
            "              foam box        150         67      0.829      0.866      0.911      0.691\n",
            "         plastic glass        150         89      0.875       0.79      0.846      0.591\n",
            "        drinking straw        150         13      0.725      0.769      0.741      0.498\n",
            "                tobaco        150         29      0.898      0.966      0.956      0.686\n",
            "         plastic spoon        150         33      0.884      0.924      0.945      0.612\n",
            "         plastic plate        150         15       0.85          1      0.935      0.607\n",
            "          plastic bowl        150         21      0.538      0.619      0.505      0.316\n",
            "           plastic cap        150          9      0.395      0.222      0.386      0.269\n",
            "           plastic box        150          8      0.728          1      0.995        0.8\n",
            "           milk bottle        150         34      0.856      0.853      0.922      0.595\n",
            "            zipper bag        150          6          1          0      0.585      0.428\n",
            "             trash bag        150        108      0.889      0.594       0.77      0.507\n",
            "                  mask        150         23      0.938      0.783      0.817      0.562\n",
            "       sausage package        150         23       0.98          1      0.995      0.612\n",
            "         snack package        150         56      0.929      0.911      0.946      0.746\n",
            "               coconut        150          2          1          0      0.105     0.0947\n",
            "instant noodle package        150          8      0.794      0.486      0.627      0.327\n",
            "          PP woven bag        150         29      0.744      0.241      0.305      0.215\n",
            "                 shoes        150          2      0.804          1      0.995      0.895\n",
            "Speed: 0.1ms pre-process, 5.1ms inference, 3.4ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights /content/drive/MyDrive/CS114/yolov5/runs/train/exp7/weights/best.pt --data /content/drive/MyDrive/CS114/Dataset/dataset.yaml  --img 640 --iou 0.45 --half --task test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClMiROmUesub"
      },
      "source": [
        "#Demo using Gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "pt0_fUmH8pa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad43eb8d-9472-4b15-9f9b-39c96d31cac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.19.1-py3-none-any.whl (14.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.5)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.25.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from gradio) (4.5.0)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.4)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from gradio) (2.1.2)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.7-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio) (3.1.2)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2023.1.0)\n",
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py[linkify]>=2.0.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.5.3)\n",
            "Collecting mdit-py-plugins<=0.3.3\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.22.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py<3,>=1\n",
            "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Collecting starlette<0.26.0,>=0.25.0\n",
            "  Downloading starlette-0.25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (2.10)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (8.1.3)\n",
            "Collecting anyio<5.0,>=3.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.12.0)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio) (3.15.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=c93565504a9bb6bf7772ec21957431df190faa73eeac38200e1012b0af874605\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: rfc3986, pydub, ffmpy, websockets, uc-micro-py, sniffio, python-multipart, pycryptodome, orjson, mdurl, h11, aiofiles, uvicorn, markdown-it-py, linkify-it-py, anyio, starlette, mdit-py-plugins, httpcore, httpx, fastapi, gradio\n",
            "Successfully installed aiofiles-23.1.0 anyio-3.6.2 fastapi-0.92.0 ffmpy-0.3.0 gradio-3.19.1 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 linkify-it-py-2.0.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.7 pycryptodome-3.17 pydub-0.25.1 python-multipart-0.0.6 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.25.0 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path= '/content/drive/MyDrive/CS114/yolov5/runs/train/exp3/weights/best.pt')\n",
        "\n",
        "# Define input and output interfaces\n",
        "def detect_objects(input_image,confidence_threshold):\n",
        "    size=640\n",
        "    input_image = input_image.resize((int(x * g) for x in input_image.size), Image.ANTIALIAS)\n",
        "    output_image = model(input_image, confidence=confidence_threshold)\n",
        "    output_image.render()\n",
        "    return Image.fromarray(output_image.imgs[0])\n",
        "\n",
        "input_img = gr.inputs.Image(type='pil', label=\"Original Image\")\n",
        "confidence_threshold = gr.inputs.Slider(minimum=0.0, maximum=1.0, default=0.45, label=\"Confidence Threshold\")\n",
        "output_interface = gr.outputs.Image(type='pil', label=\"Output Image\")\n",
        "gr.Interface(fn = detect_objects, inputs=[input_img,confidence_threshold], outputs=output_interface, title=\"Trash Classification\").launch()"
      ],
      "metadata": {
        "id": "YGyMh9zd2Rby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "outputId": "21b565f4-122b-454c-daf8-d0e144999e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"setuptools>=65.5.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.8/dist-packages (67.4.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/drive/MyDrive/CS114/yolov5/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 v7.0-116-g5c91dae Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7085641 parameters, 0 gradients, 16.0 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7867, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzqDfaIv5RS8"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/CS114/yolov5/runs/train/exp7/weights/best.pt --img 640 --conf 0.45 --source /content/drive/MyDrive/CS114/Dataset/images/test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "img_dir = '/content/drive/MyDrive/CS114/yolov5/runs/detect/exp'\n",
        "img_files = os.listdir(img_dir)\n",
        "\n",
        "for img_file in img_files:\n",
        "    if img_file.endswith(('.jpg', '.JPG')):\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        cv2_imshow(img)"
      ],
      "metadata": {
        "id": "_DzFYiEKV0WG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}